{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68df233e-5962-48e6-898e-b28a4f2d1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9604d29-1e09-4fc4-aeea-93b41ee23959",
   "metadata": {},
   "source": [
    "Sentence tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ed2307d-229e-499f-94f0-e5e39fcfa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9bfbc58-3d48-4683-bf06-8ff0a16f7abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's go to N.Y.!\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "402d6889-161f-43a6-98cf-67dc94ef9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for toekn in doc:\n",
    "    print(toekn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bf39447-fdf3-48c6-8419-3560b7e40043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "264656d5-7088-4b52-b157-43befa3d4e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.lang.en.English, spacy.tokens.doc.Doc)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp),type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "baab2a27-ac28-4a87-89d6-6cde6eb732d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's go to"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84aecbee-3836-4309-ac5a-393b83bd1c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = doc[-1]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "906609a0-48a9-4c53-9316-c5b2387a5535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c2fffba-c5a9-43cd-be99-6eba683b99f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5b2f487-682d-47c6-a2cd-38859c1bdde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fd56df4-ff17-44ce-88d8-d6879aed1714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This  is  a  list  of  words  amith.kannur777@gmail.com'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example list of strings\n",
    "text_list = [\"This\", \"is\", \"a\", \"list\", \"of\", \"words\",\"amith.kannur777@gmail.com\"]\n",
    "\n",
    "# Join the list elements with double spaces as separators\n",
    "joined_text = '  '.join(text_list)\n",
    "\n",
    "joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46216948-0e4a-4a24-be69-142339cb73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amith.kannur777@gmail.com']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(joined_text)\n",
    "emails = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8381db7b-10d7-4a71-be16-5b0f7cfa370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.blank('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48e0a7ae-a99b-4587-9017-3dd0f1670cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('मेरा नाम अमिथ हई. मुजे 1 दता स्स्चिएन्तिस्त होन प्सन्ध हेइ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddf8283b-625a-487c-8153-bb11afb37bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मेरा False\n",
      "नाम False\n",
      "अमिथ False\n",
      "हई False\n",
      ". False\n",
      "मुजे False\n",
      "1 True\n",
      "दता False\n",
      "स्स्चिएन्तिस्त False\n",
      "होन False\n",
      "प्सन्ध False\n",
      "हेइ False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87193f64-80c2-4e96-803f-4d89f30db20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मेरा',\n",
       " 'नाम',\n",
       " 'अमिथ',\n",
       " 'हई',\n",
       " '.',\n",
       " 'मुजे',\n",
       " '1',\n",
       " 'दता',\n",
       " 'स्स्चिएन्तिस्त',\n",
       " 'होन',\n",
       " 'प्सन्ध',\n",
       " 'हेइ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [x.text for x in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "331adae1-9b9b-4f2f-817a-8fb98234e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('gimme gimme gimme some time to think. i am in a bathroom looking at you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8b5f31f-a871-409a-8ff5-f52c166bda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f13c550-0771-43fc-ab19-86bf8acb2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case('gimme',[\n",
    "    {ORTH:\"gim\"},\n",
    "    {ORTH:\"me\"}\n",
    "])\n",
    "doc = nlp('gimme gimme gimme some time to think. i am in a bathroom looking at you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27bb1324-e937-42e5-acba-1e1ae4a96400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim',\n",
       " 'me',\n",
       " 'gim',\n",
       " 'me',\n",
       " 'gim',\n",
       " 'me',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'think',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'in',\n",
       " 'a',\n",
       " 'bathroom',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'you']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [x.text for x in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0ea4867-3e8e-4294-85a2-b1f6eb759601",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentencizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Envs\\workshop\\Lib\\site-packages\\spacy\\language.py:803\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    801\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n\u001b[1;32m--> 803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE007\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names))\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Overriding pipe name in the config is not supported and will be ignored.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[1;31mValueError\u001b[0m: [E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54401209-106e-4d42-aba1-b8be265f1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "670534a0-e725-4230-bcf5-aa116c247654",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('my. hgsshjhdidh. shwhdgwdhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d9ae9ef-c707-4189-b4cd-a3f5a1578660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[my., hgsshjhdidh., shwhdgwdhd]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [x for x in doc.sents]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d81d1-0c71-43c0-b2e1-ce9ec8e9efc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad3df1-30b3-44fc-83fc-9218fab68c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d05b0-2cea-4be4-90e2-54446ecdfd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
